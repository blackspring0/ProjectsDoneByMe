{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7W9dcPZdSyC"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WZvT_xTKrYr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows',None)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime as dt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsSMJIEK_Ua"
      },
      "source": [
        "storing csv as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh721QARKrUS"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRAQIL-0NcYj"
      },
      "source": [
        "# Data Fields\n",
        "\n",
        "**datetime** - hourly date + timestamp  \n",
        "\n",
        "**season**-  1 = spring, 2 = summer, 3 = fall, 4 = winter\n",
        "\n",
        "**holiday** - whether the day is considered a holiday\n",
        "\n",
        "**workingday** - whether the day is neither a weekend nor holiday\n",
        "\n",
        "**weather** - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "\n",
        "**temp** - temperature in Celsius\n",
        "\n",
        "**atemp**- \"feels like\" temperature in Celsius\n",
        "\n",
        "**humidity** - relative humidity\n",
        "\n",
        "**windspeed** - wind speed\n",
        "\n",
        "**casual** - number of non-registered user rentals initiated\n",
        "\n",
        "**registered** - number of registered user rentals initiated\n",
        "\n",
        "**count** - number of total rentals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHuJhkE3LD2-"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIPYGSphymiR"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF_UlD49LH9f"
      },
      "outputs": [],
      "source": [
        "print('Shape of Train: ',train.shape)\n",
        "print('Shape of Test: ',test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqJ80J3tMF-x"
      },
      "source": [
        "there are two columns missing in the test.\n",
        "casual,registered,i will drop them.\n",
        "count is our target column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji0kaShrNHHT"
      },
      "outputs": [],
      "source": [
        "train.drop(columns=['casual','registered'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBcJBDKrRS8w"
      },
      "outputs": [],
      "source": [
        "print('Null values in Train: \\n',train.isnull().sum())\n",
        "print('Null values in Test: \\n',test.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLMakDo3SQlC"
      },
      "source": [
        "No missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GUj6Ye9Savb"
      },
      "source": [
        "combine train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5ac8P0nR6fc"
      },
      "outputs": [],
      "source": [
        "df=pd.concat([train,test]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQ7HZFg_1KPk"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0CZiZrlQ4Qz"
      },
      "source": [
        "Lets convert datetime to month and hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhiwjaydRW1h"
      },
      "outputs": [],
      "source": [
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "\n",
        "\n",
        "df['hour'] = df['datetime'].dt.hour\n",
        "df['year'] = df['datetime'].dt.year\n",
        "\n",
        "df['month'] = df['datetime'].dt.month\n",
        "\n",
        "df.drop(columns=['datetime'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5_oQ0pjRZD0"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzdbPYI2H8ou"
      },
      "source": [
        "Plotting continous variables on a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn7qKZg22TJd"
      },
      "outputs": [],
      "source": [
        "df0=df[['temp','atemp','humidity','windspeed','count']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHydTcFc19Kq"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df0.corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFENTUBgI1nK"
      },
      "source": [
        "lets plot categorical variables versus count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90LfSjqcI6DN"
      },
      "outputs": [],
      "source": [
        "categorical_variable=['season','weather','holiday','workingday','month','weekday','hour']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfM61TnhLkpc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "for index,feature in enumerate(categorical_variable):\n",
        "  plt.subplot(5, 4, index+1)\n",
        "  sns.barplot(x=feature, y='count', data=df)\n",
        "  plt.xlabel(f'{feature}')\n",
        "  plt.ylabel('Categorical Variable')\n",
        "  plt.title(f'{feature} vs count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8gG_1T0zq0d"
      },
      "source": [
        "convert month,season,weather and hour into categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSVjrOcCzvAd"
      },
      "outputs": [],
      "source": [
        "df_with_dummies = pd.get_dummies(df, columns=['year','month', 'hour','season','weather'], drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6N84z3PYNgI"
      },
      "source": [
        "plotting continous variables vs count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc3KSxBzYRez"
      },
      "outputs": [],
      "source": [
        "continous_variable=['temp','humidity','windspeed']\n",
        "plt.figure(figsize=(30,30))\n",
        "for index,feature in enumerate(continous_variable):\n",
        "  plt.subplot(5, 4, index+1)\n",
        "  plt.scatter(df[feature], df['count'])\n",
        "  plt.xlabel(f'{feature}')\n",
        "  plt.ylabel('count')\n",
        "  plt.title('continous varible vs count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4v7a1VGowLm"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFHi7EilpNO1"
      },
      "source": [
        "lets find the feature importance also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSshkI4ipQr9"
      },
      "outputs": [],
      "source": [
        "train_data = df[df['count'].notnull()]\n",
        "test_data = df[df['count'].isnull()]\n",
        "\n",
        "\n",
        "X_train = train_data.drop(columns=['count'])\n",
        "y_train = train_data['count']\n",
        "X_test = test_data.drop(columns=['count'])\n",
        "\n",
        "\n",
        "cb_rgr = CatBoostRegressor(silent=True)\n",
        "cb_rgr.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = cb_rgr.feature_importances_\n",
        "\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
        "\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, order=feature_importance_df.sort_values('Importance', ascending=False)['Feature'])\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxrruJtqa-iU"
      },
      "source": [
        "this is a regression problem.so lets use the follwing with grid search\n",
        "\n",
        "\n",
        "*   XGBoost\n",
        "*   CatBoost\n",
        "*   Adaboost\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN1CtXHHa9H5"
      },
      "outputs": [],
      "source": [
        "print('df_final shape:', df.shape)\n",
        "print('df_train shape:', train.shape)\n",
        "print('df_test shape:',  test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ3lv1m0awxA"
      },
      "outputs": [],
      "source": [
        "X_Train = pd.DataFrame(df[:10886])\n",
        "X_Test  = pd.DataFrame(df[10886:])\n",
        "Y_Train = train['count']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_eqwWhXczKk"
      },
      "outputs": [],
      "source": [
        "print('\\nCheck that the datasets are consistent:\\n')\n",
        "print('X_train shape', X_Train.shape)\n",
        "print('Y_train shape:', Y_Train.shape)\n",
        "print('X_test shape:',  X_Test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seeVbrVOc9WT"
      },
      "outputs": [],
      "source": [
        "X_Train.drop(columns=['count'],inplace=True)\n",
        "X_Test.drop(columns=['count'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRiQGIF3YTOi"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_Train)\n",
        "X_train_scaled = scaler.transform(X_Train)\n",
        "X_test_scaled = scaler.transform(X_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdhPWyW0dAVi"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train_scaled, Y_Train, train_size=0.9, test_size=0.1,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghnd_X8P30Ky"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "models = {\n",
        "    'XGBoost': XGBRegressor(),\n",
        "    'CatBoost': CatBoostRegressor(silent=True),\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "param_grids = {\n",
        "    'XGBoost': {\n",
        "        'n_estimators': [100,150, 200,250, 300],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [4, 5,6]\n",
        "    },\n",
        "    'CatBoost': {\n",
        "        'iterations': [100,150, 200,250, 300],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'depth': [5, 6, 7]\n",
        "    }\n",
        "\n",
        "    }\n",
        "\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Training {model_name}...\")\n",
        "    grid_search = GridSearchCV(model, param_grids[model_name], scoring='neg_mean_squared_error', cv=6)\n",
        "    grid_search.fit(X_train, Y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "\n",
        "    y_pred = abs(best_model.predict(X_valid))\n",
        "    rmsle = np.sqrt(metrics.mean_squared_log_error(Y_valid,y_pred))\n",
        "    results[model_name] = rmsle\n",
        "    print(f\"{model_name}: RMSLE = {rmsle}\")\n",
        "\n",
        "\n",
        "best_model_name = min(results, key=results.get)\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "best_model.fit(X_train, Y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-ckEPinZ-iI"
      },
      "outputs": [],
      "source": [
        "predictions =best_model.predict(X_test_scaled)\n",
        "res_list = []\n",
        "for x in predictions:\n",
        "    if x<0:\n",
        "      res_list.append(0)\n",
        "    else:\n",
        "      res_list.append(x)\n",
        "predictions = np.array(res_list)\n",
        "predictions_df = pd.DataFrame({'datetime': test['datetime'], 'count': predictions})\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}