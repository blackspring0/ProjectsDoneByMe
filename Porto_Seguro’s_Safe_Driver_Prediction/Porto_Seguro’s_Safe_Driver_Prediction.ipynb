{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T3vt0QENlO5"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eBmZLuyNyVH"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c porto-seguro-safe-driver-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDjXOKbOGjI"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/porto-seguro-safe-driver-prediction.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy0YO6bMPLns"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_rows',None)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xUIYCpqPYy0"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsgkw1dLP7_2"
      },
      "outputs": [],
      "source": [
        "print('Shape of Training Dataset:',train.shape)\n",
        "print('Shape of Test Dataset:',test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target values"
      ],
      "metadata": {
        "id": "e3Np0ZHPfT7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('List of values in target feature: ' ,train['target'].unique())\n",
        "print('Count of values in target feature: \\n',train['target'].value_counts())"
      ],
      "metadata": {
        "id": "bzmWmq2nfTLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Target feature"
      ],
      "metadata": {
        "id": "RhjGUK2PXRN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRdEJA8MP9qk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "train['target'].value_counts().plot(kind='bar',color=['blue','orange'])\n",
        "plt.title('Distribution of Target')\n",
        "plt.xlabel('Target Value')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is highly imbalanced"
      ],
      "metadata": {
        "id": "tBBNYCkVXXFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should balance it using SMOTE and shuffle the dataframe"
      ],
      "metadata": {
        "id": "6V-AJKyHZEd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = train.drop(columns=['target'])\n",
        "y= train['target']\n",
        "\n",
        "\n",
        "sm = SMOTE(random_state=12, sampling_strategy=1.0)\n",
        "\n",
        "x1, y1= sm.fit_resample(x, y)\n",
        "\n",
        "oversampled_df = pd.concat([pd.DataFrame(x1, columns=x.columns), pd.Series(y1, name='target')], axis=1)\n",
        "\n",
        "oversampled_df = oversampled_df.sample(frac=1).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "JDLY2bFWZDuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oversampled_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "OS4Fs83vnsLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class imbalance is solved"
      ],
      "metadata": {
        "id": "JjQEVz6cpW_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dealing 5 lakhs of rows requires high computational resources,So I will take only 15000 samples."
      ],
      "metadata": {
        "id": "yUMx5zwEpchh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 15000\n",
        "sample_df = oversampled_df.sample(n=sample_size, random_state=42)"
      ],
      "metadata": {
        "id": "Xv9NGfcxqc-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sample_df['target'].value_counts().plot(kind='bar',color=['blue','orange'])\n",
        "plt.title('Distribution of Target')\n",
        "plt.xlabel('Target Value')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UKiTGDph7J6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace -1 which is in the dataframe for missing values.we need to replace is with \"nan\""
      ],
      "metadata": {
        "id": "9R8iulDlqf_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=sample_df .copy()"
      ],
      "metadata": {
        "id": "sbNlk7e7pmvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns0Q1dj7Sgf9"
      },
      "outputs": [],
      "source": [
        "df.replace(-1, np.nan, inplace=True)\n",
        "test.replace(-1, np.nan, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking for null values"
      ],
      "metadata": {
        "id": "PaE0Q52dp05p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2rMVp7cTPv4"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSh3T4IDTwzB"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['ps_car_03_cat','ps_car_05_cat'],inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8uMD6UTgyM1"
      },
      "outputs": [],
      "source": [
        "test.drop(columns=['ps_car_03_cat','ps_car_05_cat'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4TOR4fXULQQ"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV-qStS_g4wc"
      },
      "outputs": [],
      "source": [
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy5SqwsrUMb2"
      },
      "outputs": [],
      "source": [
        "categorical_features_to_impute=['ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_car_01_cat','ps_car_02_cat','ps_car_07_cat','ps_car_09_cat']\n",
        "continous_features_to_impute=['ps_reg_03','ps_car_14']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP2lybauheHz"
      },
      "outputs": [],
      "source": [
        "continous_features_to_impute_test=['ps_reg_03','ps_car_14','ps_car_11']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMJZmGRPVXYm"
      },
      "outputs": [],
      "source": [
        "for feature in continous_features_to_impute:\n",
        "    df[feature].fillna(df[feature].mean(), inplace=True)\n",
        "\n",
        "\n",
        "for feature in categorical_features_to_impute:\n",
        "    mode_val = df[feature].mode()[0]\n",
        "    df[feature].fillna(mode_val, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhuJORkThbb4"
      },
      "outputs": [],
      "source": [
        "for feature in continous_features_to_impute_test:\n",
        "    test[feature].fillna(test[feature].mean(), inplace=True)\n",
        "for feature in categorical_features_to_impute:\n",
        "    mode_val = test[feature].mode()[0]\n",
        "    test[feature].fillna(mode_val, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkyLriJ-VmNA"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg-ibs69h0WP"
      },
      "outputs": [],
      "source": [
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make copies of train and test data"
      ],
      "metadata": {
        "id": "l4M1csKg75Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0=df.copy()\n",
        "test0=test.copy()"
      ],
      "metadata": {
        "id": "ye2mS-uS74VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd3UxsD6VfKY"
      },
      "outputs": [],
      "source": [
        "df0.drop(columns=['id'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXQEGFHai-RD"
      },
      "outputs": [],
      "source": [
        "test0.drop(columns=['id'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3enpF3Fh8j3i"
      },
      "outputs": [],
      "source": [
        "print('df0 shape:', df0.shape)\n",
        "print('test0 shape:', test0.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBAZdPNNVG5S"
      },
      "outputs": [],
      "source": [
        "y = df0['target']\n",
        "X=df0.drop(columns=['target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzzoRq20n0mr"
      },
      "outputs": [],
      "source": [
        "print('y shape:', y.shape)\n",
        "print('X shape:',  X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgBH1ibiVnuu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8, test_size=0.2,random_state=0,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for each model\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 5, 10]\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'n_estimators': [50, 100, 200],\n",
        "        'learning_rate': [0.01, 0.1, 0.5]\n",
        "    },\n",
        "    'Decision Tree': {\n",
        "        'max_depth': [None, 5, 10],\n",
        "        'min_samples_split': [2, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train each model with GridSearchCV\n",
        "trained_models_gs = {}\n",
        "for name, model in models.items():\n",
        "    if name in param_grids:\n",
        "        grid_search = GridSearchCV(model, param_grids[name], scoring='roc_auc', cv=5)\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        trained_models_gs[name] = grid_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        trained_models_gs[name] = model\n",
        "\n",
        "# 3. Evaluation\n",
        "# Same evaluation as before\n",
        "\n",
        "# 4. Gini Score Calculation\n",
        "auc_scores_gs = {}\n",
        "for name, model in trained_models_gs.items():\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    auc_scores_gs[name] = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate Gini score\n",
        "gini_scores_gs = {name: 2 * auc - 1 for name, auc in auc_scores_gs.items()}\n",
        "\n",
        "# 5. Model Selection\n",
        "best_model_name_gs = max(gini_scores_gs, key=gini_scores_gs.get)\n",
        "best_model_gs = trained_models_gs[best_model_name_gs]\n",
        "\n",
        "print(\"Best Model with GridSearchCV:\", best_model_name_gs)\n",
        "print(\"Gini Score of Best Model with GridSearchCV:\", gini_scores_gs[best_model_name_gs])\n"
      ],
      "metadata": {
        "id": "coORAEDy-Vrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_id = test['id']\n",
        "\n",
        "# Make predictions on the sample\n",
        "predictions = model.predict(test0)\n",
        "\n",
        "# Create a dataframe with 'id' and 'target' columns\n",
        "predictions_df = pd.DataFrame({'id': sample_id, 'target': predictions})\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "XwKgWfpoBDED"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}