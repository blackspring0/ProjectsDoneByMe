{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T3vt0QENlO5"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eBmZLuyNyVH"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download -c porto-seguro-safe-driver-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyDjXOKbOGjI"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/porto-seguro-safe-driver-prediction.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy0YO6bMPLns"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_rows',None)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import make_scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xUIYCpqPYy0"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv('train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsgkw1dLP7_2"
      },
      "outputs": [],
      "source": [
        "print('Shape of Training Dataset:',train.shape)\n",
        "print('Shape of Test Dataset:',test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "combining train and test"
      ],
      "metadata": {
        "id": "1nlxUr2XxUMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0=[train,test]\n",
        "df=pd.concat(df0).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-yfEu5QvxTYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Combined dataframe: ',df.shape)"
      ],
      "metadata": {
        "id": "Q1YfB5OSx56x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target values"
      ],
      "metadata": {
        "id": "e3Np0ZHPfT7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('List of values in target feature: ' ,df['target'].unique())\n",
        "print('Count of values in target feature: \\n',df['target'].value_counts())"
      ],
      "metadata": {
        "id": "bzmWmq2nfTLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Target feature"
      ],
      "metadata": {
        "id": "RhjGUK2PXRN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRdEJA8MP9qk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "train['target'].value_counts().plot(kind='bar',color=['blue','orange'])\n",
        "plt.title('Distribution of Target')\n",
        "plt.xlabel('Target Value')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is highly imbalanced,so either we can balance it using sampling or we can conduct strong feature engineering.I prefer second."
      ],
      "metadata": {
        "id": "tBBNYCkVXXFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace -1 which is in the dataframe for missing values.we need to replace it with \"nan\""
      ],
      "metadata": {
        "id": "9R8iulDlqf_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns0Q1dj7Sgf9"
      },
      "outputs": [],
      "source": [
        "df.replace(-1, np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking for null values"
      ],
      "metadata": {
        "id": "PaE0Q52dp05p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2rMVp7cTPv4"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here two features has more than or almost 50% missing values,we can remove those features"
      ],
      "metadata": {
        "id": "3FrlUs3Z4eU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSh3T4IDTwzB"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['ps_car_03_cat','ps_car_05_cat'],inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for remaining missing values,we can impute with mean for continous features and with mode for categorical.binary features does not have missing values,so we dont have to impute."
      ],
      "metadata": {
        "id": "IzJIfX6A4uL5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy5SqwsrUMb2"
      },
      "outputs": [],
      "source": [
        "categorical_features_to_impute=['ps_ind_02_cat','ps_ind_04_cat','ps_ind_05_cat','ps_car_01_cat','ps_car_02_cat','ps_car_07_cat','ps_car_09_cat']\n",
        "continous_features_to_impute=['ps_reg_03','ps_car_11','ps_car_12','ps_car_14']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMJZmGRPVXYm"
      },
      "outputs": [],
      "source": [
        "for feature in continous_features_to_impute:\n",
        "    df[feature].fillna(df[feature].mean(), inplace=True)\n",
        "\n",
        "\n",
        "for feature in categorical_features_to_impute:\n",
        "    mode_val = df[feature].mode()[0]\n",
        "    df[feature].fillna(mode_val, inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Combined dataframe: ',df.shape)"
      ],
      "metadata": {
        "id": "vA5YtzB6FoNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkyLriJ-VmNA"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there is no missing values,but since the dataset is very big,we cannot train it using all these features,so we need carefully do the feature engineering\n",
        "\n",
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "l4M1csKg75Ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot importance of features"
      ],
      "metadata": {
        "id": "Hz2QuAVOuiUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = df[df['target'].notnull()]\n",
        "test_data = df[df['target'].isnull()]\n",
        "\n",
        "\n",
        "X_train = train_data.drop(columns=['target'])\n",
        "y_train = train_data['target']\n",
        "X_test = test_data.drop(columns=['target'])\n",
        "\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = rf_clf.feature_importances_\n",
        "\n",
        "\n",
        "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
        "\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, order=feature_importance_df.sort_values('Importance', ascending=False)['Feature'])\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "t3Ta9g9_ufvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_list = feature_importance_df['Feature'].tolist()"
      ],
      "metadata": {
        "id": "eFxYlAbF7BLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected = df[training_list]\n",
        "plt.figure(figsize=(30, 30))\n",
        "sns.heatmap(df_selected.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap of Selected Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v6m0KNqHkcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that the feature which ends with 'calc' has almost zero corelation with other features,so we can drop it"
      ],
      "metadata": {
        "id": "CEPrHwbDPE19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_subset = feature_importance_df[~feature_importance_df['Feature'].str.contains('calc')]"
      ],
      "metadata": {
        "id": "I9RgQ5-oTfvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_list2 = training_subset['Feature'].tolist()"
      ],
      "metadata": {
        "id": "AaWcE0idQqqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train the model"
      ],
      "metadata": {
        "id": "wXxEX9x7PYEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=train[training_list2].copy()\n",
        "y=train['target']\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7tW-bErNLsiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_score(y_true, y_prob):\n",
        "    return 2 * roc_auc_score(y_true, y_prob) - 1\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier()\n",
        "lgbm_clf = LGBMClassifier()\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "xgb_train_scores = []\n",
        "xgb_valid_scores = []\n",
        "lgbm_train_scores = []\n",
        "lgbm_valid_scores = []\n",
        "\n",
        "\n",
        "for train_index, valid_index in cv.split(X, y):\n",
        "    X_train_fold, X_valid_fold = X.iloc[train_index], X.iloc[valid_index]\n",
        "    y_train_fold, y_valid_fold = y.iloc[train_index], y.iloc[valid_index]\n",
        "\n",
        "    xgb_clf.fit(X_train_fold, y_train_fold)\n",
        "    xgb_train_pred_proba = xgb_clf.predict_proba(X_train_fold)[:, 1]\n",
        "    xgb_valid_pred_proba = xgb_clf.predict_proba(X_valid_fold)[:, 1]\n",
        "    xgb_train_score = gini_score(y_train_fold, xgb_train_pred_proba)\n",
        "    xgb_valid_score = gini_score(y_valid_fold, xgb_valid_pred_proba)\n",
        "    xgb_train_scores.append(xgb_train_score)\n",
        "    xgb_valid_scores.append(xgb_valid_score)\n",
        "\n",
        "    lgbm_clf.fit(X_train_fold, y_train_fold)\n",
        "    lgbm_train_pred_proba = lgbm_clf.predict_proba(X_train_fold)[:, 1]\n",
        "    lgbm_valid_pred_proba = lgbm_clf.predict_proba(X_valid_fold)[:, 1]\n",
        "    lgbm_train_score = gini_score(y_train_fold, lgbm_train_pred_proba)\n",
        "    lgbm_valid_score = gini_score(y_valid_fold, lgbm_valid_pred_proba)\n",
        "    lgbm_train_scores.append(lgbm_train_score)\n",
        "    lgbm_valid_scores.append(lgbm_valid_score)\n",
        "\n",
        "mean_xgb_train_score = np.mean(xgb_train_scores)\n",
        "mean_xgb_valid_score = np.mean(xgb_valid_scores)\n",
        "mean_lgbm_train_score = np.mean(lgbm_train_scores)\n",
        "mean_lgbm_valid_score = np.mean(lgbm_valid_scores)\n",
        "\n",
        "print(\"Mean XGBoost training gini score:\", mean_xgb_train_score)\n",
        "print(\"Mean XGBoost validation gini score:\", mean_xgb_valid_score)\n",
        "print(\"Mean LightGBM training gini score:\", mean_lgbm_train_score)\n",
        "print(\"Mean LightGBM validation gini score:\", mean_lgbm_valid_score)"
      ],
      "metadata": {
        "id": "NXohZ6E8KERG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict unseen data and make the submission file"
      ],
      "metadata": {
        "id": "41036PDQP2LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unseen_data=X_test[training_list2]\n",
        "xgb_unseen_pred_proba = xgb_clf.predict_proba(unseen_data)[:, 1]\n",
        "lgbm_unseen_pred_proba = lgbm_clf.predict_proba(unseen_data)[:, 1]\n",
        "predictions_df = pd.DataFrame({\n",
        "    'id': unseen_data['id'],\n",
        "    'target_xgb': xgb_unseen_pred_proba,\n",
        "    'target_lgbm': lgbm_unseen_pred_proba\n",
        "})\n",
        "predictions_df['target'] = (predictions_df['target_xgb'] + predictions_df['target_lgbm']) / 2\n",
        "predictions_df[['id', 'target']].to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "BCD1uApqNE7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}